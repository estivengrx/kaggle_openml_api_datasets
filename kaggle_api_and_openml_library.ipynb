{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\"id\": 7306260, \"ref\": \"aryan208/student-habits-and-academic-performance-dataset\", \"subtitle\": \"Analyze how habits and mental health shape student success.\", \"creatorName\": \"Aryan Kumar\", \"creatorUrl\": \"aryan208\", \"totalBytes\": 2994172, \"url\": \"https://www.kaggle.com/datasets/aryan208/student-habits-and-academic-performance-dataset\", \"lastUpdated\": \"2025-05-02T00:27:34.627Z\", \"downloadCount\": 6614, \"isPrivate\": false, \"isFeatured\": false, \"licenseName\": \"CC0: Public Domain\", \"description\": \"\", \"ownerName\": \"Aryan Kumar\", \"ownerRef\": \"aryan208\", \"kernelCount\": 5, \"title\": \"Student Habits and Academic Performance Dataset\", \"topicCount\": 0, \"viewCount\": 26831, \"voteCount\": 58, \"currentVersionNumber\": 1, \"usabilityRating\": 1.0, \"tags\": [{\"ref\": \"education\", \"name\": \"education\", \"description\": \"Education datasets and kernels relate to statistics on student performance, university rankings, and answers for all your homework questions.\", \"fullPath\": \"subject > people and society > education\", \"competitionCount\": 60, \"datasetCount\": 35778, \"scriptCount\": 15142, \"totalCount\": 50980}, {\"ref\": \"computer science\", \"name\": \"computer science\", \"description\": \"There is one thing we can say for sure about computer science: Computer science leads to more computer games which leads to better GPUs which leads to smarter AI.\", \"fullPath\": \"subject > science and technology > computer science\", \"competitionCount\": 16, \"datasetCount\": 57897, \"scriptCount\": 776, \"totalCount\": 58689}], \"files\": [], \"versions\": []}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VwFefXQhyiT"
      },
      "source": [
        "# Kaggle datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZtKzXVqUFoj",
        "outputId": "6fd76d59-6ebd-4d8e-fe18-d86cc413d1bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.4/160.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Move the kaggle.json API file to the .kaggle directory for authentication\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "#Changing permissions on the file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "#Installing openml and xlswriter packages\n",
        "#PD: xlswriter will be useful to treat links in the excel files\n",
        "!pip install openml XlsxWriter --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2iyNW2--Ootx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openml, xlsxwriter, os\n",
        "\n",
        "from warnings import filterwarnings\n",
        "\n",
        "filterwarnings(\"ignore\")\n",
        "# kaggle.api.authenticate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1WTEOW5cdHE"
      },
      "source": [
        "Creating the dataframe that will hold the name of the dataset, file name, description and link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EPPZ-iVWOouQ"
      },
      "outputs": [],
      "source": [
        "main_records = pd.DataFrame(columns=['title', 'file-name', 'description', 'link'])\n",
        "main_records.to_excel('datasets_information.xlsx',\n",
        "                      index=None,\n",
        "                      engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "dfpezYSYOouh",
        "outputId": "b4a4e458-94f0-4e35-92f3-40e48f81dc34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>file-name</th>\n",
              "      <th>description</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, file-name, description, link]\n",
              "Index: []"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main_records = pd.read_excel('datasets_information.xlsx')\n",
        "main_records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOasp_-NcoXG"
      },
      "source": [
        "Searching the datasets through the kaggle database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f5542ZfOous",
        "outputId": "ef59017c-87b9-4511-ebd6-1550e77dd7fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.15 / client 1.5.13)\n",
            "11\n"
          ]
        }
      ],
      "source": [
        "datasets_names = []\n",
        "\n",
        "#keywords to search for datasets\n",
        "search_terms = ['physics']\n",
        "\n",
        "#Retrieving dataset names to be dowloaded\n",
        "for word in search_terms:\n",
        "    datasets = [kaggle.api.dataset_list(page=page, search=word, max_size=1_000) for page in range(1, 2)]\n",
        "    for list_object in datasets:\n",
        "        for datasetname in list_object:\n",
        "            datasets_names.append(datasetname)\n",
        "\n",
        "print(len(datasets_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_Xdn18mOovG"
      },
      "outputs": [],
      "source": [
        "folder_path = \"data\"\n",
        "\n",
        "for data in datasets_names:\n",
        "    if (data.title not in list(main_records['title'])) \\\n",
        "        and (data.url not in list(main_records['link'])):\n",
        "\n",
        "        #Licences of the datasets that will be allowed to be downloaded\n",
        "        #In this case: public domain licences\n",
        "        if vars(data)['licenseName'] in [\"Database: Open Database\", \"Contents: Database Contents\", \\\n",
        "                                        \"CC0: Public Domain\", \"GLP\", \"GLP2\", \\\n",
        "                                        \"Community Data License Agreement - Sharing - Version 1.0\", \\\n",
        "                                        \"GNU Lesser General Public License 3.0\"]:\n",
        "\n",
        "            #Information that we will want to be in the final dataframe\n",
        "            title = vars(data)['title']\n",
        "            file_name = str(data).split('/')[1]\n",
        "            description = kaggle.api.dataset_view(data.ref).description\n",
        "            link = vars(data)['url']\n",
        "\n",
        "            main_records = pd.concat([main_records,\n",
        "                                      pd.DataFrame({'title': [title],\n",
        "                                                    'file-name': [file_name],\n",
        "                                                    'description': [description],\n",
        "                                                    'link':[link]})])\n",
        "\n",
        "            #Downloading the data\n",
        "            directory = '/content/data'\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            \n",
        "            kaggle.api.dataset_download_files(data.ref,\n",
        "                                              path='/content/data',\n",
        "                                              unzip=False)\n",
        "\n",
        "            archivo_zip = str(data).split('/')[1] + '.zip'\n",
        "            folder_name = os.path.splitext(archivo_zip)[0]\n",
        "\n",
        "        else: pass\n",
        "    else: pass\n",
        "\n",
        "main_records.to_excel('datasets_information.xlsx',\n",
        "                      index=None,\n",
        "                      engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0psdLvH7e2Pv"
      },
      "source": [
        "Backup code to save the dataframe to excel file if the above code throws a warning or error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GxsVOhwcOovL"
      },
      "outputs": [],
      "source": [
        "main_records.to_excel('datasets_information.xlsx',\n",
        "                      index=None,\n",
        "                      engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urNOMfHThvpw"
      },
      "source": [
        "# OpenML datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbKTQPODo2PA"
      },
      "source": [
        "Mainly, this OpenML database contain supervised learning datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n300nIqvoR19"
      },
      "source": [
        "Creation of the dataframe that will contain the files information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w8P6P6H7Oovq"
      },
      "outputs": [],
      "source": [
        "openml_records = pd.DataFrame(columns=['title', 'file-name', 'description', 'link'])\n",
        "openml_records.to_excel('./openml_datasets_information.xlsx',\n",
        "                        index=None,\n",
        "                        engine=\"xlsxwriter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "-7tkexsph9FM",
        "outputId": "94b66c00-9d7c-4408-d72e-19b8d6b53c0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>file-name</th>\n",
              "      <th>description</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, file-name, description, link]\n",
              "Index: []"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openml_records = pd.read_excel('openml_datasets_information.xlsx')\n",
        "openml_records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3McElLmUOov1",
        "outputId": "f63a2a3a-102c-4478-85dd-b0ee0a735517"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not download file from http://openml1.win.tue.nl/dataset33/dataset_33.pq: HTTPConnectionPool(host='openml1.win.tue.nl', port=80): Max retries exceeded with url: /dataset33/dataset_33.pq (Caused by ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))\n"
          ]
        }
      ],
      "source": [
        "range_of_index = range(30, 45)\n",
        "\n",
        "for dataset_index in range_of_index:\n",
        "    try:\n",
        "        dataset_info = openml.datasets.get_dataset(dataset_id=dataset_index, download_data=False)\n",
        "        if (dataset_info.name not in list(openml_records['title'])) \\\n",
        "        and (dataset_info.url not in list(openml_records['link'])):\n",
        "\n",
        "            title = dataset_info.name\n",
        "            description = dataset_info.description\n",
        "            link = dataset_info.original_data_url\n",
        "\n",
        "            openml_records = pd.concat([openml_records,\n",
        "                                        pd.DataFrame({'title': [title],\n",
        "                                                      'file-name': [title],\n",
        "                                                      'description': [description],\n",
        "                                                      'link':[link]})])\n",
        "\n",
        "            #Turning the data into a dataframe format\n",
        "            X, y, categorical_indicator, attribute_names = dataset_info.get_data(\n",
        "            dataset_format=\"array\", target=dataset_info.default_target_attribute)\n",
        "            df = pd.DataFrame(X, columns=attribute_names)\n",
        "            df[\"class\"] = y\n",
        "\n",
        "            directory = '/content/openmldata'\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "            df.to_csv('/content/openmldata/' + title + '.csv')\n",
        "        else: pass\n",
        "\n",
        "    except openml.exceptions.OpenMLPrivateDatasetError:\n",
        "        print(f\"The dataset {dataset_index} is private and cannot be accessed.\")\n",
        "        pass\n",
        "openml_records.to_excel('openml_datasets_information.xlsx',\n",
        "                        index=None,\n",
        "                        engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GqzkJMMfwMoT"
      },
      "outputs": [],
      "source": [
        "openml_records.to_excel('openml_datasets_information.xlsx',\n",
        "                        index=None,\n",
        "                        engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Successfully saved requirements file in d:\\Estiven\\Datos\\Proyectos\\kaggle_openml_api\\requirements.txt\n"
          ]
        }
      ],
      "source": [
        "!pipreqs --force"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
